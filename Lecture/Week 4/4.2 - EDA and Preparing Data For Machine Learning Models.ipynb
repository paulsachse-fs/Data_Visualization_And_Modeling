{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "**Exploratory Data Analysis (EDA)** is an approach to analyzing datasets to summarize their main characteristics, often using visual methods. It allows you to understand the data, get a sense of the structure, relationships between variables, identify outliers, detect anomalies, test hypothesis, or check assumptions related to a specific model.  It's an important step on the way to doing machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History of EDA\n",
    "\n",
    "The term \"Exploratory Data Analysis\" was coined by John W. Tukey in the 1970s. Tukey played a significant role in developing the field of statistics. He highlighted the importance of using a more visual approach in analyzing datasets, rather than focusing primarily on traditional statistical methods. \n",
    "\n",
    "In his pioneering work, \"Exploratory Data Analysis\" (1977), Tukey proposed that data analysis should begin by exploring the data, rather than by confirming a hypothesis. He introduced various graphical techniques, like the box plot and stem-and-leaf plot, as well as other methods that allow analysts to visualize and understand the underlying structure of their data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance of EDA\n",
    "\n",
    "1. **Understanding Data Distribution**: Before applying any ML model, you need to understand the distribution of your data. Some algorithms make assumptions about the distribution of your data, such as linear regression assuming that the residuals are normally distributed.\n",
    "\n",
    "2. **Feature Engineering**: EDA can reveal insights that guide the transformation or creation of new features to improve the performance of machine learning models.\n",
    "\n",
    "3. **Detecting Outliers**: Outliers can skew statistical measures and are typically removed or adjusted for before modeling.\n",
    "\n",
    "4. **Data Cleaning**: EDA can help in spotting missing or erroneous data. Clean data is crucial for the success of a machine learning model.\n",
    "\n",
    "5. **Choosing the Right Model**: Some patterns in the data can help decide if a linear model, time-series model, clustering algorithm, etc., might be more appropriate.\n",
    "\n",
    "6. **Validating Assumptions**: Many models have underlying assumptions. For example, if you're planning to use methods that assume a linear relationship between variables, it's good to verify this assumption through EDA.\n",
    "\n",
    "7. **Reducing Overfitting**: By understanding the actual relationships and patterns in data, we can create models that generalize better. If we build models without understanding these relationships, we risk overfitting to noise or outliers in the data.\n",
    "\n",
    "### EDA before Machine Learning\n",
    "\n",
    "Doing EDA before modeling in machine learning is crucial for several reasons:\n",
    "\n",
    "1. **Improving Model Performance**: Understanding the nature of your data can lead to better feature selection and, consequently, better model performance.\n",
    "  \n",
    "2. **Efficiency**: EDA can prevent you from going down dead-end paths or making erroneous decisions based on misconceptions about the data.\n",
    "\n",
    "3. **Storytelling**: A key aspect of data science and analytics is the ability to convey a story. EDA allows you to understand this story before moving to modeling.\n",
    "\n",
    "4. **Trustworthiness**: By performing EDA, you assure stakeholders that the data was thoroughly inspected before any models were built, lending credibility to your findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AirBnB data\n",
    "\n",
    "Airbnb, launched in 2008, is a platform that allows individuals to rent out their properties or spare rooms to guests. The company has grown rapidly and has become a major player in the hospitality industry. Airbnb's open nature means that anyone with space can become a host, leading to an incredible diversity of listings worldwide.\n",
    "\n",
    "This dataset has was compiled and updated on  which has columns describing features such as host id, hostname, listing id, listing name, latitude and longitude of listing, the neighbourhood, price, room type, minimum number of nights, number of reviews, last review date, reviews per month, availability, host listings and city.  The AirBnB data has been used for many machine learning projects.  \n",
    "\n",
    "**Let's say you are working for a start-up that advises individuals who are considering starting a side hustle with AirBnB.**  You are planning to develop a model that predicts that price an individual can charge for the listing based on factors like the location, minimum number of nights it is offered, availablility, how many reviews the property has and the name given to the listing.\n",
    "\n",
    "How are these factors related to the price of a listing?  What type of advice should your company give to clients if they want a listing that commands the highest price?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data and install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: missingno in c:\\users\\paul_\\anaconda3\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from missingno) (2.1.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from missingno) (3.10.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from missingno) (1.15.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from missingno) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.17.0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from seaborn->missingno) (2.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn->missingno) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\paul_\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn->missingno) (2025.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install missingno\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import plotly.express as ps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check for missing data\n",
    "\n",
    "Why is it important to check for missing data?\n",
    "\n",
    "**Algorithm Compatibility:** Many machine learning algorithms can't handle missing values and will throw an error if you try to fit them with data containing NaN values. You will experience the classic \"Input contains NaN\" error if you've forgotten this step.\n",
    "\n",
    "**Data Quality and Integrity:** Missing data can be an indication of a broader problem with the data collection, processing, or storage processes. Before training any model, it's essential to ensure that the data's quality is up to the mark.\n",
    "\n",
    "**Biased Results:** Missing values, if not handled properly, can introduce bias in ML models. This can be especially the case if data is not missing completely at random. For instance, if certain types of observations are more likely to have missing data than others, models trained on such data can lead to biased predictions or interpretations.\n",
    "\n",
    "**Model Performance:** Improper handling of missing values can degrade the model's performance. If missing values are replaced with a constant value without much thought, the variance and relationship dynamics of the data can be altered, leading to poorer model performance.\n",
    "\n",
    "**Loss of Valuable Information:** Simply removing rows or columns with missing values can lead to a significant loss of information. Before deciding on such a step, it's essential to evaluate the potential impact.\n",
    "\n",
    "**Feature Engineering:** Handling missing values often requires an understanding of the domain and the specific features. Sometimes, the fact that a value is missing can itself be informative. Creating an additional binary \"indicator\" feature that denotes whether a value was missing can sometimes add predictive power.\n",
    "\n",
    "**Computational Efficiency:** Some methods of handling missing values, like model-based imputation, can be computationally expensive. It's important to be aware of missing values early on to allocate resources efficiently.\n",
    "\n",
    "**Evaluation Metrics:** Like outliers, missing values, if not addressed properly, can distort evaluation metrics. This can mislead the model selection and evaluation process.\n",
    "\n",
    "**Model Interpretability:** Missing values can make it challenging to interpret a model's behavior, especially if different features have missing data in different ways.\n",
    "\n",
    "**Statistical Assumptions:** Some algorithms, like those used for imputation (e.g., regression imputation), make assumptions about the nature of the data. Missing values can violate these assumptions and impact the integrity of the imputation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've talked some different ways to print the number of missing values using Pandas (`.info()`, `.isnull().sum()`).  However, sometimes it's important to understand not only how much data is missing but how missing data is distributed.  Are only a few individuals missing a lot of data?  Or is the missing data sprinkled throughout the entire dataset? \n",
    "\n",
    "To get a better understanding of how missing data in our data, we can use a new visualization called the msno.matrix function from the missingno library is used to create a \"nullity matrix\" of your data.  Here's a breakdown of what the nullity matrix does and how to interpret it:\n",
    "\n",
    "Graphical Representation: The nullity matrix provides a binary, graphical representation of your dataset, where:\n",
    "\n",
    "* The light (often white) lines or blocks represent missing values.\n",
    "* The dark (often black) lines or blocks represent non-missing (filled) values.\n",
    "* Columns: Each column of the matrix corresponds to a column in your DataFrame. If you see a column with many white lines, it means that this column has a significant amount of missing data.\n",
    "* Rows: Each row of the matrix corresponds to a row in your DataFrame. If a row has many white blocks, it means that this particular row has many missing values.\n",
    "* Data Density: On the right side of the matrix, you might notice a sparkline-style mini plot. This plot provides a summarized view of the data completeness for each row. Rows at the top of the matrix with more dark blocks will have a higher line on the sparkline than rows at the bottom with more missing data.\n",
    "\n",
    "The visual representation is beneficial because it quickly gives you an overview of where you're missing data and how much.  Patterns in missing data can be indicative of a structured problem in the data collection process. For instance, if you notice that two columns are always missing data together, it might indicate an issue you weren't aware of.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is data missing?\n",
    "\n",
    "### 1. Missing Completely at Random (MCAR)\n",
    "\n",
    "**Definition:**\n",
    "The probability that an observation is missing is the same for all units—i.e. missingness has **no relationship** to any observed or unobserved data.\n",
    "\n",
    "**Implication:**\n",
    "Dropping MCAR cases (complete‑case analysis) produces unbiased estimates, though with reduced power.\n",
    "\n",
    "**Example scenarios:**\n",
    "\n",
    "* A lab technician accidentally spills some blood samples at random, so those measurements are lost.\n",
    "* A survey sheet is lost in the mail for a random subset of participants, irrespective of who they are or how they would have answered.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Missing at Random (MAR)\n",
    "\n",
    "**Definition:**\n",
    "The probability of missingness **may depend on observed data** but is independent of the unobserved (missing) values themselves, conditional on those observed data.\n",
    "\n",
    "**Implication:**\n",
    "If you correctly model (or condition on) the variables related to missingness, you can obtain unbiased estimates (e.g. via multiple imputation, inverse‑probability weighting).\n",
    "\n",
    "**Example scenarios:**\n",
    "\n",
    "* In a health survey, older participants are less likely to report their income, but among participants of the same age the chance of missing income doesn’t depend on their actual income level.\n",
    "* Students with lower GPAs are less likely to fill out an optional feedback form, but within each GPA bracket, missingness doesn’t depend further on the specific feedback they would have given.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Missing Not at Random (MNAR)\n",
    "\n",
    "**Definition:**\n",
    "The probability of missingness **depends on the unobserved value itself**, even after accounting for all observed data.\n",
    "\n",
    "**Implication:**\n",
    "Standard methods (complete‑case, MAR‑based imputation) will generally be biased. You need specialized models (e.g. selection models, pattern‑mixture models) or strong assumptions to handle MNAR.\n",
    "\n",
    "**Example scenarios:**\n",
    "\n",
    "* In a depression questionnaire, patients with **more severe** symptoms are **less likely** to complete the survey (i.e. the missingness increases as the true depression score rises).\n",
    "* People with **very high** incomes choose not to report their salary, even after conditioning on age, education, and occupation.\n",
    "\n",
    "---\n",
    "\n",
    "| Mechanism | Missingness depends on…       |   Bias if ignored?   | Typical remedy                 |\n",
    "| :-------: | :---------------------------- | :------------------: | :----------------------------- |\n",
    "|  **MCAR** | Nothing (purely random)       |          No          | Complete‑case                  |\n",
    "|  **MAR**  | Observed data (e.g. age, GPA) | Yes (unless modeled) | Multiple imputation, weighting |\n",
    "|  **MNAR** | Unobserved (missing) values   |          Yes         | MNAR‑specific models           |\n",
    "\n",
    "---\n",
    "\n",
    "### Key takeaway\n",
    "\n",
    "* **MCAR** is the “best” (rarest) case: missingness is pure noise.\n",
    "* **MAR** is common and manageable if you include the right predictors of missingness.\n",
    "* **MNAR** is the hardest: you must explicitly model the missing‑data mechanism itself or invoke strong, unverifiable assumptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What feature has the most missing data?\n",
    "Are there any features that are missing in tandem?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Examine the distribution of 'Price'.  \n",
    "\n",
    "What is a typical price for an AirBnB rental?  What is the range of prices people charge for rentals?  Is the distribution of price skewed?  Let's make a boxplot and histogram of price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Identify outliers\n",
    "\n",
    "One thing is clear - there are some very expensive AirBnB listings out there!\n",
    "\n",
    "Say we know our potential customers are likely to want to purchase a property that can be rented for less than $500 per night. \n",
    "\n",
    "Let's filter the data to remove very high priced listings and plot the distribution of price again.  Removing outliers isn't always the right thing to do; however, in this case, it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of AirBnB rentals under `$500` dollars is skewed to the right with a mean of `$163` and a median of `$138`. The price range is from `$0` to `$499.00`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Understand the distribution of other catgorical and quantitative features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m categorical_features:\n\u001b[0;32m     11\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m---> 12\u001b[0m     sns\u001b[38;5;241m.\u001b[39mcountplot(data\u001b[38;5;241m=\u001b[39mdf, y\u001b[38;5;241m=\u001b[39mfeature, order\u001b[38;5;241m=\u001b[39mdf[feature]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m     14\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistribution of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_titles[feature]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m     plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_titles[feature]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar plots for key categorical variables\n",
    "categorical_features = ['room_type', 'neighbourhood_group', 'city']\n",
    "\n",
    "feature_titles = {\n",
    "    'room_type': 'Room Type',\n",
    "    'neighbourhood_group': 'Neighborhood Group',\n",
    "    'city': 'City'\n",
    "}\n",
    "\n",
    "for feature in categorical_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=df, y=feature, order=df[feature].value_counts().index)\n",
    "    \n",
    "    plt.title(f\"Distribution of {feature_titles[feature]}\")\n",
    "    plt.ylabel(f\"{feature_titles[feature]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most AirBnBs are entire apartment/houses or private rooms.  However there are some shared and hotel rooms available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Boxplots of quantitative features\n",
    "\n",
    "quantitative_features = ['minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
    "\n",
    "feature_titles = {\n",
    "    'minimum_nights': 'Minimum Nights',\n",
    "    'number_of_reviews': 'Number of Reviews',\n",
    "    'reviews_per_month': 'Reviews per Month',\n",
    "    'calculated_host_listings_count': 'Number of Host Listings',\n",
    "    'availability_365': 'Number of Days Available Each Year', \n",
    "    'number_of_reviews_ltm': 'Number of Reviews LTM'\n",
    "}\n",
    "\n",
    "for feature in quantitative_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df, x=feature)\n",
    "    plt.title(f\"Distribution of {feature_titles[feature]}\")\n",
    "    plt.xlabel('Number')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the features (except Available_365) are heavily skewed to the right where most properties have low values and a few have very high values.\n",
    "\n",
    "Let's say you know your clients will want a place that is intended to be rented for - at most - a month at a time.  Let's filter the data once more so that the minimum nights is 31 or less.  \n",
    "\n",
    "Your clients also know that they only want this to be a side-hustle, not something they do professionally, so it doesn't make sense to include listings owned by people or corporations that hold more than 10 properties.  Let's also filter the data so that the host listings count is 10 or less.\n",
    "\n",
    "Then let's look at the distribution of price and other features again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.loc[ (df['minimum_nights'] <= 31) & (df['calculated_host_listings_count'] <=10) & (df['reviews_per_month'] <= 31) ]\n",
    "\n",
    "# Bar plots for key categorical variables\n",
    "categorical_features = ['room_type', 'neighbourhood_group', 'city']\n",
    "\n",
    "feature_titles = {\n",
    "    'room_type': 'Room Type',\n",
    "    'neighbourhood_group': 'Neighborhood Group',\n",
    "    'city': 'City'\n",
    "}\n",
    "\n",
    "for feature in categorical_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=df, y=feature, order=df[feature].value_counts().index)\n",
    "    \n",
    "    plt.title(f\"Distribution of {feature_titles[feature]}\")\n",
    "    plt.ylabel(f\"{feature_titles[feature]}\")\n",
    "    plt.show()\n",
    "    \n",
    "#Boxplots of quantitative feat\n",
    "quantitative_features = ['price','minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
    "\n",
    "feature_titles = {\n",
    "    'price': 'Price in USD',\n",
    "    'minimum_nights': 'Minimum Nights',\n",
    "    'number_of_reviews': 'Number of Reviews',\n",
    "    'reviews_per_month': 'Reviews Per Month',\n",
    "    'calculated_host_listings_count': 'Number of Host Listings',\n",
    "    'availability_365': 'Number of Days Available Each Year', \n",
    "    'number_of_reviews_ltm': 'Number of Reviews'\n",
    "}\n",
    "\n",
    "for feature in quantitative_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df, x=feature)\n",
    "    plt.title(f\"Distribution of {feature_titles[feature]}\")\n",
    "    plt.xlabel('Number of Listings')\n",
    "    plt.show()\n",
    "    \n",
    "print(df['price'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most listings that fit the criteria we established above are still entire homes and apartments with a few shared and hotel rooms.  Most of them are listed in NY City and LA.  The median number of nights listed is less than 5.  The mean price per night is `$160` and the median price is `$133`.  Most have less than 100 reviews and the distribution of the number of the number of available nights per year is evenly spread between 1 and 365."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['minimum_nights'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Example the relationship of other features to price.\n",
    "\n",
    "Now that we have the right dataset for the type of model we want to build, we can start looking at relationships in the data that are associated with price.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[df['room_type'] == 'Entire home/apt']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x='reviews_per_month', y='price', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median price for a hotel room and for the entire house/apartment are higher than for either a private room or shared room.  Because the plots of price by neighborhood and city are so busy, it's hard to tell if one city/neighborhood commands a higher price than the others, though the higher median price for a rental in the Washington neighborhood look promising.\n",
    "\n",
    "Because they command the highest price and are more straightforward to purchase, your clients want to focus specifically on entire house/apartment rentals.  Let's filter the data once more to only include listings that are a whole house/apartment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x='price', y='neighbourhood_group', data=df)\n",
    "plt.ylabel('Neighborhood Group')\n",
    "plt.xlabel('Price in USD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='price', y='city', data=df)\n",
    "plt.ylabel('Neighborhood Group')\n",
    "plt.xlabel('Price in USD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at all of the listings nationwide, there aren't any clear patterns between the minimum number of nights required, number of reviews, or number of days available and price.  It's possible that's because relationships exist specifically on a local level. \n",
    "\n",
    "**Earlier we saw that the median price in the Washington neighborhood was higher than the median price of other neighborhoods.  Let's focus on that.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "# switch to a compatible renderer\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "import plotly.express as px\n",
    "washington = df[df['neighbourhood_group'] == 'Washington']\n",
    "\n",
    "center_lat = washington['latitude'].mean()\n",
    "center_lon = washington['longitude'].mean()\n",
    "\n",
    "min_p, max_p = washington['price'].min(), washington['price'].max()\n",
    "\n",
    "# build the figure\n",
    "fig = px.scatter_map(\n",
    "    washington,\n",
    "    lat='latitude',\n",
    "    lon='longitude',\n",
    "    color='price',\n",
    "    size='price',\n",
    "    range_color=[min_p, max_p],\n",
    "    size_max=15,\n",
    "    zoom=9,\n",
    "    map_style='open-street-map',\n",
    "    center={'lat': center_lat, 'lon': center_lon},\n",
    "    height=500,\n",
    "    title='Washington Neighborhood AirBnBs'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "areas = df[df['neighbourhood_group'] == 'Unincorporated Areas']\n",
    "\n",
    "center_lat = areas['latitude'].mean()\n",
    "center_lon = areas['longitude'].mean()\n",
    "\n",
    "min_p, max_p = areas['price'].min(), areas['price'].max()\n",
    "\n",
    "# build the figure\n",
    "fig = px.scatter_map(\n",
    "    areas,\n",
    "    lat='latitude',\n",
    "    lon='longitude',\n",
    "    color='price',\n",
    "    size='price',\n",
    "    range_color=[min_p, max_p],\n",
    "    size_max=15,\n",
    "    zoom=9,\n",
    "    map_style='open-street-map',\n",
    "    center={'lat': center_lat, 'lon': center_lon},\n",
    "    height=500,\n",
    "    title='Washington Neighborhood AirBnBs'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see a few patterns emerging.  Listings with a minimum stay under about 7 days tend to command higher prices.  There is a curved relationship between number of reviews and prices where inexpensive rentals get a lot of reviews.  There doesn't seem to be any relationship between price and availability.\n",
    "\n",
    "Now that we've focused on a single geographic area, we can zoom in and see how prices differ within the Washington neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like many of the highest priced rentals are along the coast or on the little island.\n",
    "\n",
    "Finally, we can see if there are any differences in the wording of the listings of higher (above the 75th percentile) and lower (< 25th percentile) price ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Examining the text in the listing names using a word cloud\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Create word cloud for 'description' column\n",
    "# This sticks the text of all the positive reviews together and all the negative reviews together in two long strings separated by spaces\n",
    "high_price = ' '.join(washington[washington['price'] > 207]['name'].astype(str))\n",
    "low_price = ' '.join(washington[washington['price'] <= 85]['name'].astype(str))\n",
    "\n",
    "\n",
    "print(\"High-priced listings:\")\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(high_price)\n",
    "plt.figure(figsize=(10, 7)) \n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Low-priced listings:\")\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(low_price)\n",
    "plt.figure(figsize=(10, 7)) \n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What recommendations would you give to the client we described in this scenario?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK\n",
    "We've reviewed many ways of visualizing data and discussed how they are important in preparing our data to be used in machine learning model.  EDA is an important and very involved part of the field of data science."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
